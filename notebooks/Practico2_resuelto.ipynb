{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "079e39e1-9b78-4b44-9743-604bf0ca5a3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Segunda parte\n",
    "\n",
    "### **4. Extracción de etiquetas**\n",
    "\n",
    "En el archivo [etiquetas.csv](https://drive.google.com/file/d/1LWY3VoIRt0xKwEbbtMXYePOGZvgPsQh-/view?usp=sharing) están las etiquetas para un pequeño subconjunto de nodos. Podemos interpretar el valor de la etiqueta como la pertenencia a una determinada clase, donde los usuarios de una misma clase en general tienden a expresar apoyo entre sí.\n",
    "\n",
    "- Determinar quiénes son los usuarios referentes de cada clase (utilizar alguna medida de centralidad calculada sobre el grafo de retweets).\n",
    "- Utiliando los resultados del práctico anterior, determinar si los usuarios de cada clase forman parte de distintas comunidades.\n",
    "\n",
    "**Opcional:** Reconstruir el archivo \"etiquetas.csv\". Para eso, hacer lo siguiente\n",
    "\n",
    "- Construir un grafo en donde los nodos sean usuarios, y donde los enlaces unan dos nodos si entre ellos hubo más respuestas de apoyo que de oposición.\n",
    "- Extraer las dos componentes más grandes del grafo. Esos serán nuestros nodos etiquetados.\n",
    "\n",
    "### **5. Embedding de nodos**\n",
    "\n",
    "- Generar un embedding del grafo de retweets utilizando el algoritmo `word2vec`.\n",
    "- Reducir a 2 la dimensionalidad del embedding utilizando [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) y [t-SNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.htmlhttps://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html).\n",
    "- Graficar los embeddings correspondientes a los datos etiquetados. ¿Es posible diferenciar unos de otros?\n",
    "\n",
    "**Opcional:** Graficar además los embeddings de los nodos que forman parte de las comunidades asociadas a cada clase. Determinar si el embedding permite distinguir cada comunidad.\n",
    "\n",
    "### **Opcional: 6. Redes neuronales de grafos**\n",
    "\n",
    "El archivo [word_vectors.csv](https://drive.google.com/file/d/1aoxugyMktKb0NQ8Pf3bdhKvh8BAj7YZz/view?usp=sharing) contiene un embedding de 300 dimensiones para cada tweet, otenido utilizando un modelo preentrenado de [FastText](https://fasttext.cc/). Construir una matriz de features para los nodos tomando, para cada usuario, el promedio de los vectores correspondientes a los tweets que escribió. Utilizando estos features, y tomando como ejemplos etiquetados los usuarios de \"etiquetas.csv\" entrenar una red neuronal de grafos para realizar una clasificación binaria sobre el resto de los nodos. Pueden utilizar como base el siguiente modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5333b57-a167-46a6-af83-95d1960921d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(1234)\n",
    "        self.conv1 = GCNConv(dataset.num_features, 4)\n",
    "        self.conv2 = GCNConv(4, 4)\n",
    "        self.conv3 = GCNConv(4, 2)\n",
    "        self.classifier = Linear(2, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv2(h, edge_index)\n",
    "        h = h.tanh()\n",
    "        h = self.conv3(h, edge_index)\n",
    "        h = h.tanh()  # Embedding final\n",
    "        \n",
    "        # Aplicamos un clasificador lineal sobre el embedding\n",
    "        out = self.classifier(h)\n",
    "\n",
    "        return out, h"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319c67f8-f2aa-4b95-8f0a-9a6c8f28b221",
   "metadata": {},
   "source": [
    "**Observación:** para alimentar la red neuronal, es necesario construir un objeto de la clase `Dataset` de PyTorch-Geometric. Una forma de hacer eso es la siguiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc2f06b-eb86-4970-ba98-618267618521",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import InMemoryDataset, Data\n",
    "\n",
    "## Reemplazar por el grafo correspondiente\n",
    "g = nx.Graph()\n",
    "\n",
    "## Etiquetas. Reemplazar por las clases del archivo 'etiquetas.csv'.\n",
    "## Asignar la clase '2' a los ejemplos no etiquetados\n",
    "labels = [1, 0, 2, ..., 1]\n",
    "\n",
    "## True si el ejemplo está etiquetado (clases 0 y 1)\n",
    "train_idx = [True, True, False, ..., True]\n",
    "\n",
    "## Matriz de features (word vectors)\n",
    "features = ...\n",
    "\n",
    "adj = nx.to_scipy_sparse_matrix(g).tocoo()\n",
    "row = torch.from_numpy(adj.row.astype(np.int64)).to(torch.long)\n",
    "col = torch.from_numpy(adj.col.astype(np.int64)).to(torch.long)\n",
    "edge_index = torch.stack([row, col], dim=0)\n",
    "\n",
    "\n",
    "class TwitterDataset(InMemoryDataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super(TwitterDataset, self).__init__('.', transform, None, None)\n",
    "\n",
    "        data = Data(edge_index=edge_index)\n",
    "        \n",
    "        data.num_nodes = g.number_of_nodes()\n",
    "        \n",
    "        # Features \n",
    "        data.x = torch.from_numpy(features).type(torch.float32)\n",
    "        \n",
    "        # Etiquetas\n",
    "        y = torch.from_numpy(labels).type(torch.long)\n",
    "        data.y = y.clone().detach()\n",
    "        \n",
    "        data.num_classes = 2\n",
    "        \n",
    "        n_nodes = g.number_of_nodes()\n",
    "        \n",
    "        # create train and test masks for data\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[train_idx] = True\n",
    "        data['train_mask'] = train_mask\n",
    "\n",
    "        self.data, self.slices = self.collate([data])\n",
    "\n",
    "    def _download(self):\n",
    "        return\n",
    "\n",
    "    def _process(self):\n",
    "        return\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}()'.format(self.__class__.__name__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:graphML] *",
   "language": "python",
   "name": "conda-env-graphML-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
